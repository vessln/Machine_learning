%matplotlib inline


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer

from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from xgboost import plot_importance

import optuna
from optuna.visualization import plot_optimization_history

from sklearn.metrics import (accuracy_score, make_scorer, f1_score, fbeta_score, roc_auc_score, precision_score, 
                                recall_score, classification_report, confusion_matrix, roc_curve, auc)

from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate

import pickle


# pip install optuna








merged_dataset = pd.read_csv("data/merged_ds.csv")
merged_dataset


merged_dataset.shape


merged_dataset.info()


merged_dataset.describe().T





for column in merged_dataset[["age", "blood_pressure", "cholesterol", "max_heart_rate", "oldpeak"]]:
    plt.figure(figsize = (6, 4))

    plt.hist(merged_dataset[column], color = 'lightblue')
    plt.title(f'{column} distribution')
    plt.xlabel(column)
    plt.ylabel('frequency')

    plt.tight_layout()
    plt.show()


merged_dataset[merged_dataset.cholesterol == 0]


merged_dataset[merged_dataset.cholesterol == 0].heart_disease.value_counts()


heart_disease_1 = merged_dataset.loc[merged_dataset['heart_disease'] == 1].copy()
heart_disease_0 = merged_dataset.loc[merged_dataset['heart_disease'] == 0].copy()

# impute zero cholesterol values for heart_disease = 1
imputer_1 = SimpleImputer(strategy = 'mean', missing_values = 0)
heart_disease_1['cholesterol'] = imputer_1.fit_transform(heart_disease_1[['cholesterol']])

# impute missing cholesterol values for heart_disease = 0
imputer_0 = SimpleImputer(strategy = 'mean', missing_values = 0)
heart_disease_0['cholesterol'] = imputer_0.fit_transform(heart_disease_0[['cholesterol']])

dataset = pd.concat([heart_disease_1, heart_disease_0], ignore_index = True)


dataset[dataset.cholesterol == 0]


dataset[dataset.blood_pressure == 0]


imp = SimpleImputer(strategy = 'mean', missing_values = 0)
dataset['blood_pressure'] = imp.fit_transform(dataset[['blood_pressure']])


'''
    I tried binning the oldpeak, but the performance was worse.
    ranges: (-inf, 1), [1, 2], (2, 3.5], (3.5, +inf)
'''

# bins = [float('-inf'), 1, 2, 3.5, float('inf')]
# labels = ['Normal', 'Mild', 'Severe', 'Critical']
# dataset['oldpeak'] = pd.cut(dataset['oldpeak'], bins = bins, labels = labels, right = True).astype('object')





for column in ['gender', 'chest_pain_type', 'high_blood_sugar', 'resting_ecg', 'exercise_angina', 'st_slope', 'heart_disease']:
    plt.figure(figsize = (6, 4))
    
    sns.countplot(x = dataset[column], hue = dataset[column], palette = 'Pastel2')
    plt.ylabel('frequency')
    plt.title(f'Bar plot for {column}')
    plt.tight_layout()
    plt.show()
    
    print(dataset[column].value_counts())





plt.figure(figsize = (6, 4))

sns.countplot(data = dataset, x = 'heart_disease', hue = dataset.gender, palette = 'Pastel2')
plt.xlabel('heart_disease')
plt.ylabel('frequency')
plt.title('Heart disease by gender')

plt.show()


round(dataset.groupby('gender')['heart_disease'].value_counts(normalize = True).unstack() * 100, 2)





with_heart_disease = dataset[dataset.heart_disease == 1]
most_risk_ages = with_heart_disease['age'].value_counts().head(5)
mean_age = np.mean(most_risk_ages.index)

most_risk_ages


print(f"In the years around {round(mean_age)} there is the greatest risk for heart disease.")


plt.figure(figsize = (6, 4))

sns.countplot(data = dataset, x = 'heart_disease', hue = dataset.exercise_angina, palette = 'Pastel2')
plt.xlabel('heart_disease')
plt.ylabel('frequency')
plt.title('Heart disease by exercise induced angina')

plt.show()


round(dataset.groupby('exercise_angina')['heart_disease'].value_counts(normalize = True).unstack() * 100, 2)





plt.figure(figsize = (6, 4))

sns.countplot(data = dataset, x = 'heart_disease', hue = dataset.st_slope, palette = 'Pastel2')
plt.xlabel('heart_disease')
plt.ylabel('frequency')
plt.title('Heart disease by st_slope')

plt.show()





without_heart_disease = dataset[dataset['heart_disease'] == 0]

plt.figure(figsize = (7, 4))
plt.hist(with_heart_disease['cholesterol'], bins = 30, label = 'with heart disease', alpha = 0.7, color = 'lightpink')
plt.hist(without_heart_disease['cholesterol'], bins = 30, label = 'without heart disease', alpha = 0.7, color = 'lightblue')
plt.xlabel('cholesterol level')
plt.ylabel('frequency')
plt.title('Cholesterol levels of people with vs without heart disease')

plt.legend()
plt.show()


print(f"Average cholesterol of people with heart disease = {round(dataset[dataset.heart_disease == 1].cholesterol.mean())}")
print(f"Average cholesterol of people without heart disease = {round(dataset[dataset.heart_disease == 0].cholesterol.mean())}")


plt.figure(figsize = (7, 4))

plt.hist(with_heart_disease['max_heart_rate'], label = 'with heart disease', alpha = 0.7, color = 'lightpink')
plt.hist(without_heart_disease['max_heart_rate'], label = 'without heart disease', alpha = 0.7, color = 'lightblue')
plt.xlabel('max heart rate')
plt.ylabel('frequency')
plt.title('Max heart rate levels of people with vs without heart disease')
plt.legend()

plt.show()


print(f"Average max heart rate of people with heart disease = {round(dataset[dataset.heart_disease == 1].max_heart_rate.mean())}")
print(f"Average max heart rate of people without heart disease = {round(dataset[dataset.heart_disease == 0].max_heart_rate.mean())}")





plt.figure(figsize = (7, 4))

plt.hist(with_heart_disease['blood_pressure'], label = 'with heart disease', alpha = 0.7, color = 'lightpink')
plt.hist(without_heart_disease['blood_pressure'], label = 'without heart disease', alpha = 0.7, color = 'lightblue')
plt.xlabel('blood pressure')
plt.ylabel('frequency')
plt.title('Blood pressure levels of people with vs without heart disease')
plt.legend()

plt.show()


print(f"Average blood pressure of people with heart disease = {round(dataset[dataset.heart_disease == 1].blood_pressure.mean())}")
print(f"Average blood pressure of people without heart disease = {round(dataset[dataset.heart_disease == 0].blood_pressure.mean())}")


plt.figure(figsize = (7, 4))

plt.hist(dataset[dataset['heart_disease'] == 1].oldpeak, bins = 8, label = 'with heart disease', alpha = 0.7, color = 'lightpink')
plt.hist(dataset[dataset['heart_disease'] == 0].oldpeak, bins = 8, label = 'without heart disease', alpha = 0.7, color = 'lightblue')
plt.xlabel('oldpeak')
plt.ylabel('frequency')
plt.title('Oldpeak levels of people with vs without heart disease')
plt.legend()

plt.show()


dataset[dataset.heart_disease == 1].oldpeak.mean()


dataset[dataset.heart_disease == 0].oldpeak.mean()








value_counts_target = dataset.heart_disease.value_counts()
plt.figure(figsize = (5, 5))

plt.pie(value_counts_target, labels = ["diseased", "healthy"], autopct = '%1.2f%%', colors = ['lightpink', 'lightblue'])
plt.title('Pie chart of the target')
plt.show()

print(value_counts_target)


dataset.info()


correlation_matrix = dataset.select_dtypes(include = ['int64', 'float64']).corr()

plt.figure(figsize = (8, 6))
sns.heatmap(correlation_matrix, annot = True, cmap = 'coolwarm', fmt = '.3g')
plt.title('Correlation matrix')

plt.show()








dataset.shape


attributes = dataset.drop('heart_disease', axis = 1)
target = dataset['heart_disease']

attrs_train, attrs_test, target_train, target_test = train_test_split(
    attributes, 
    target, 
    test_size = 0.25,
    random_state = 42, 
    stratify = target) 











# Log transformation for columns cholesterol and blood_pressure, because they have positive skew

# preprocessor = ColumnTransformer(
#     transformers = [
#         ('cat', OneHotEncoder(drop = 'first', sparse_output = False), ['gender', 'exercise_angina']),
#         ('mcat', OneHotEncoder(drop = "first", categories = [['ATA', 'NAP', 'ASY', 'TA']]), ['chest_pain_type']),
#         ('ord', OrdinalEncoder(categories = [
#             ['Normal', 'ST', 'LVH'],                    # for resting_ecg
#             ['Normal', 'Mild', 'Severe', 'Critical'],   # for oldpeak
#             ['Up', 'Flat', 'Down']                      # for st_slope
#         ]), ['resting_ecg', 'oldpeak', 'st_slope']),
#         ('log_transform', FunctionTransformer(np.log1p), ['blood_pressure', 'cholesterol']),
#         ('scaling', StandardScaler(), ['blood_pressure', 'cholesterol', 'max_heart_rate', 'age']),
#         ('passthrough', 'passthrough', ['high_blood_sugar']),
#     ]
# )

# poor performance with these transformations


preprocessor = ColumnTransformer(
    transformers = [
        ('cat', OneHotEncoder(drop = 'first', sparse_output = False), ['gender', 'exercise_angina']),
        ('mcat', OneHotEncoder(drop = "first", categories = [['ATA', 'NAP', 'ASY', 'TA']]), ['chest_pain_type']),
        ('ord', OrdinalEncoder(categories = [['Normal', 'ST', 'LVH'], ['Up', 'Flat', 'Down']]), ['resting_ecg', 'st_slope']),
        ('scaling', StandardScaler(), ['blood_pressure', 'cholesterol', 'max_heart_rate', 'age', 'oldpeak']),
        ('passthrough', 'passthrough', ['high_blood_sugar']),
    ]
)


preprocessor





def objective(trial):
    model_type = trial.suggest_categorical('classifier', ['DecisionTree', 'LogisticRegression', 'RandomForest', 'XGBoost', 'SVM'])
    
    if model_type == 'DecisionTree':
        classifier = DecisionTreeClassifier(
            max_depth = trial.suggest_int('max_depth', 2, 15),
            min_samples_split = trial.suggest_int('min_samples_split', 2, 10),
            min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5),
            criterion = trial.suggest_categorical('criterion', ['gini', 'entropy']),
            random_state = 42
        )  

    elif model_type == 'LogisticRegression':
        penalty = trial.suggest_categorical('penalty', ['l2', 'l1', 'elasticnet'])
        classifier = LogisticRegression(
            C = trial.suggest_float('C', 1e-2, 1e2, log = True),
            penalty = penalty,
            l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0) if penalty == 'elasticnet' else None,
            max_iter = 1000,
            solver = 'saga',
            class_weight = 'balanced',
            random_state = 42
        )

    elif model_type == 'RandomForest':
        classifier = RandomForestClassifier(
            max_depth = trial.suggest_int('max_depth', 2, 30),
            n_estimators = trial.suggest_int('n_estimators', 50, 500),
            min_samples_split = trial.suggest_int('min_samples_split', 2, 10),
            min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5),
            class_weight = 'balanced',
            random_state = 42
        ) 
        
    elif model_type == 'XGBoost':
        classifier = XGBClassifier(
            max_depth = trial.suggest_int('max_depth', 2, 30),
            gamma = trial.suggest_float('gamma', 0, 5),
            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1.0, log = True),
            n_estimators = trial.suggest_int('n_estimators', 50, 500),
            subsample = trial.suggest_float('subsample', 0.5, 1.0),
            colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0),
            reg_alpha = trial.suggest_float('reg_alpha', 0, 10), 
            reg_lambda = trial.suggest_float('reg_lambda', 0, 10),
            random_state = 42
        )
        
    elif model_type == 'SVM':
        classifier = SVC(
            C = trial.suggest_float("C", 1e-4, 1e2, log = True),
            kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf']),
            probability= True,
            random_state = 42
        )
        
    pipeline = ImbPipeline([
        ('preprocessor', preprocessor),
        ('smote', SMOTE(sampling_strategy = 'minority', random_state = 42)),
        ('classifier', classifier),
    ])

    scoring = {'roc_auc': 'roc_auc', 'f1': 'f1', 'accuracy': 'accuracy'}

    scores = cross_validate(pipeline, attrs_train, target_train, cv = 5, scoring = scoring, return_train_score=False, return_estimator=True)

    preds = cross_val_predict(pipeline, attrs_train, target_train, cv = 5)
    cm = confusion_matrix(target_train, preds)
    
    trial.set_user_attr('roc_auc', scores['test_roc_auc'].mean())
    trial.set_user_attr('f1_score', scores['test_f1'].mean())
    trial.set_user_attr('accuracy', scores['test_accuracy'].mean())
    trial.set_user_attr('confusion_matrix', np.array2string(cm))

    return scores['test_roc_auc'].mean()


study = optuna.create_study(study_name = 'models_optimization', direction = 'maximize')
study.optimize(objective, n_trials = 200)
print(f"Best parameters: {study.best_params}\nwith optimization score: roc_auc = {study.best_value}")
best_trial = study.best_trial


best_params = {}

for trial in study.trials:
    classifier = trial.params['classifier']
    if classifier not in best_params or trial.value > best_params[classifier]['score']:
        best_params[classifier] = {
            'params': trial.params, 
            'score': trial.value,
            'f1_score': trial.user_attrs['f1_score'],
            'accuracy': trial.user_attrs['accuracy'],
            'cm': trial.user_attrs['confusion_matrix']
        }

for classifier, result in best_params.items():
    print(f"Classifier: {classifier}\nBest parameters: {result['params']}\nRoc_auc score: {result['score']}")
    print(f"F1-score: {result['f1_score']}\nAccuracy: {result['accuracy']}\nConfusion_matrix:\n {result['cm']}\n")


plot_optimization_history(study).show()





def train_and_plot_roc(models_params, X_train, y_train, X_test, y_test, preprocessor):
    plt.figure(figsize = (8, 6))

    for model_name, model_data in models_params.items():
        params = model_data['params']
        classifier_type = params.pop('classifier')

        if classifier_type == 'RandomForest':
            model = RandomForestClassifier(**params, class_weight = 'balanced', random_state = 42)
        elif classifier_type == 'XGBoost':
            model = XGBClassifier(**params, random_state = 42)
        elif classifier_type == 'SVM':
            model = SVC(**params, probability = True, random_state = 42)
        elif classifier_type == 'DecisionTree':
            model = DecisionTreeClassifier(**params, random_state = 42)
        elif classifier_type == 'LogisticRegression':
            model = LogisticRegression(**params, solver = 'saga', class_weight = 'balanced', max_iter = 1000, random_state = 42)

        final_pipeline = ImbPipeline([
            ('preprocessor', preprocessor),
            ('smote', SMOTE(sampling_strategy = 'minority', random_state = 42)),
            ('classifier', model)
        ])

        final_pipeline.fit(X_train, y_train)
        y_probs = final_pipeline.predict_proba(X_test)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_probs)
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, lw = 2, label = f'{model_name} (AUC = {roc_auc:.3f})')

    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random (AUC = 0.5)')

    plt.xlabel('False Positive Rate', fontsize=12)
    plt.ylabel('True Positive Rate', fontsize=12)
    plt.title('ROC AUC comparison for different models', fontsize=14)
    plt.legend(loc = 'lower right', fontsize = 10)
    plt.grid(alpha = 0.3)
    plt.savefig('img/roc_curves.png')
    plt.show()


train_and_plot_roc(best_params, attrs_train, target_train, attrs_test, target_test, preprocessor)





params = best_params['XGBoost']['params']
xgb_model = XGBClassifier(**params, random_state = 42)

final_pipeline = ImbPipeline([
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state = 42)),
    ('classifier', xgb_model)
])

final_pipeline.fit(attrs_train, target_train)
test_preds = final_pipeline.predict(attrs_test)

accuracy = accuracy_score(target_test, test_preds)
f1 = f1_score(target_test, test_preds)
recall = recall_score(target_test, test_preds)
precision = precision_score(target_test, test_preds)
cm = confusion_matrix(target_test, test_preds)
report = classification_report(target_test, test_preds)

print(f"Model performance on test set:")
print(f"Accuracy: {accuracy:.4f}")
print(f"F1-score: {f1:.4f}")
print(f"Recall: {recall:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Classification report:\n{report}")

plt.figure(figsize = (5, 4))
sns.heatmap(cm, annot=True, fmt='.0f', cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion matrix')
plt.savefig('img/cm.png')
plt.show()








feature_names = []
for transformer_name, transformer, columns in final_pipeline.named_steps['preprocessor'].transformers_:
    if transformer == 'drop':
        continue
    if hasattr(transformer, 'get_feature_names_out'): 
        feature_names.extend(transformer.get_feature_names_out(columns))
    else:
        feature_names.extend(columns)

feature_names = pd.Series(feature_names)

xgb_model = final_pipeline.named_steps['classifier']
xgb_model.get_booster().feature_names = feature_names.tolist()





plt.figure(figsize = (6, 4))
plot_importance(xgb_model, values_format = '{v:.2f}', height = 0.4, importance_type = 'gain', color = 'green', title='Feature importances')
plt.savefig('img/xgb_fi.png')
plt.show()


# save the best model
with open('xgb_model.pkl', 'wb') as file:
    pickle.dump(xgb_model, file)



