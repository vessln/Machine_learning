%matplotlib inline


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import fetch_california_housing

from sklearn.preprocessing import MinMaxScaler, StandardScaler

from sklearn.linear_model import LinearRegression, RANSACRegressor








dataset = fetch_california_housing(as_frame=True)


dataset.keys()


print(dataset.DESCR)


house_prices_df = dataset.frame


house_prices_df





plt.hist(house_prices_df.MedInc, bins = "fd")
plt.xlabel("value * $ 10^{4} $")
plt.ylabel("frequency")
plt.show()


house_prices_df[house_prices_df.MedInc > 15].sort_values("MedInc")








house_prices_df.corr()


plt.hist(house_prices_df.HouseAge, bins = "fd")
plt.xlabel("age")
plt.ylabel("frequency")
plt.show()


house_prices_df.HouseAge.value_counts()


plt.hist(house_prices_df.AveOccup, bins = "fd")
plt.xlabel("number of people in house")
plt.ylabel("frequency")
plt.show()


'''
    The logarithmic transformation is often used in data analysis when the distribution of values ​​is asymmetric or skewed.
    If most values ​​are small, but there are a few large values ​​(outliers), a logarithmic transformation will make the 
    distribution more balanced and closer to normal. This makes the analysis easier and the histogram more informative.
'''
plt.hist(np.log10(house_prices_df.AveOccup), bins = "fd")
plt.xlabel("number of people in house")
plt.ylabel("frequency")
plt.show()


# outliars:
house_prices_df[np.log10(house_prices_df.AveOccup) > 1.5].sort_values("AveOccup")


# lets check the target:
plt.hist(house_prices_df.MedHouseVal, bins = "fd")
plt.xlabel("value * $ 10^{5} $")
plt.ylabel("frequency")
plt.show()


house_prices_df[house_prices_df.MedHouseVal > 5].MedHouseVal.unique()





house_prices_df = house_prices_df[house_prices_df.MedHouseVal <= 5]





hp_model = LinearRegression()


hp_attributes = house_prices_df.drop(columns = ["MedHouseVal"])
house_values = house_prices_df.MedHouseVal # target


hp_model.fit(hp_attributes, house_values)


hp_model.coef_


hp_model.feature_names_in_


list(zip(hp_model.feature_names_in_, hp_model.coef_))











# the distribution remains the same (бъ дефаулт: feature_range=(0, 1))
scaler = MinMaxScaler()


# learn the data with .fit()
# scales the values ​​to be between 0 and 1 with .transform()
hp_attributes_scaled = scaler.fit_transform(hp_attributes)


hp_model_scaled = LinearRegression()


hp_model_scaled.fit(hp_attributes_scaled, house_values)


list(zip(hp_model.feature_names_in_, hp_model_scaled.coef_))








z_score_attributes = StandardScaler().fit_transform(hp_attributes)


z_score_model = LinearRegression()


z_score_attributes.shape


z_score_model.fit(z_score_attributes, house_values)


list(zip(hp_model.feature_names_in_, z_score_model.coef_))


z_score_model.score(z_score_attributes, house_values)








ransac_model = RANSACRegressor()


ransac_model.fit(hp_attributes_scaled, house_values)


ransac_model.estimator_.coef_


# returns only inliers:
ransac_model.inlier_mask_


hp_attributes[ransac_model.inlier_mask_]


# returns only outliers:
hp_attributes[~ransac_model.inlier_mask_]


hp_model_scaled.score(hp_attributes_scaled, house_values)


ransac_model.score(hp_attributes_scaled, house_values)


ransac_model.score(hp_attributes_scaled[ransac_model.inlier_mask_], house_values[ransac_model.inlier_mask_])





def test_RANSAC_params(rt = None):
    ransac_model_2 = RANSACRegressor(residual_threshold = rt)
    ransac_model_2.fit(hp_attributes_scaled, house_values)
    return f"inliers = {ransac_model_2.inlier_mask_.sum() / len(hp_attributes_scaled)}%"


test_RANSAC_params()


test_RANSAC_params(rt = 0.1)


test_RANSAC_params(rt = 0.5)


test_RANSAC_params(rt = 1)





ransac_model_3 = RANSACRegressor(residual_threshold = 0.1, min_samples = 10000, max_trials = 1000)
ransac_model_3.fit(hp_attributes_scaled, house_values)
ransac_model_3.inlier_mask_.sum() / len(hp_attributes_scaled)









